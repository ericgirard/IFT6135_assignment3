{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "import scipy.io\n",
    "import imageio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from classify_svhn import *\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=256):\n",
    "        return input.view(input.size(0), size, 4, 4)\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input size is 3x32x32\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size = 32x32x32\n",
    "            nn.Conv2d(32, 64, 4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size = 64x16x16\n",
    "            nn.Conv2d(64, 256, 4, 2, 1,bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size = 256 x 8 x 8\n",
    "            nn.Conv2d(256, 512, 4, 2, 1,bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size = 512 x 4 x 4\n",
    "            nn.Conv2d(512, 1, 4, 1, 0,bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 512 x 4 x 4\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 256 x 8 x 8\n",
    "            nn.ConvTranspose2d(256, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 64 x 16 x 16\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 32 x 32 x 32\n",
    "            nn.ConvTranspose2d(32, 3, 3, 1, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. 3 x 32 x 32\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=256, z_dim=100):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            \n",
    "            # input size is 3x32x32\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size = 32x32x32\n",
    "            nn.Conv2d(32, 64, 4, 2, 1,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size = 64x16x16\n",
    "            nn.Conv2d(64, 256, 4, 2, 1,bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size = 256 x 8 x 8\n",
    "            nn.Conv2d(256, 512, 4, 2, 1,bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size = 512 x 4 x 4\n",
    "            nn.Conv2d(512, 256, 4, 1, 0,bias=False),\n",
    "            # state size = 1024 x 1 x 1\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.flat = Flatten()\n",
    "        self.unflat = UnFlatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(256, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 512 x 4 x 4\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 256 x 8 x 8\n",
    "            nn.ConvTranspose2d(256, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 64 x 16 x 16\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 32 x 32 x 32\n",
    "            nn.ConvTranspose2d(32, 3, 3, 1, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. 3 x 32 x 32\n",
    "        )\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size()).to(device)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "#         print(h.size())\n",
    "        h = self.flat(h)\n",
    "#         print(h.size())\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    " \n",
    "        z = self.fc3(z)\n",
    "#         print(z.size())\n",
    "        z = z.view([z.size(0), 256, 1, 1])\n",
    "#         print(z.size())\n",
    "        z = self.decoder(z)\n",
    "#         print(z.size())\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used:  cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (5): Conv2d(64, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used: \", device)\n",
    "\n",
    "#LOAD VAE\n",
    "model_vae = VAE()\n",
    "model_vae.load_state_dict(torch.load('vae.torch'))\n",
    "model_vae.to(device)\n",
    "model_vae.eval()\n",
    "\n",
    "#LOAD GAN GENERATOR\n",
    "model_gen = Generator()\n",
    "model_gen.load_state_dict(torch.load('gan_gen.torch'))\n",
    "model_gen.to(device)\n",
    "model_gen.eval()\n",
    "\n",
    "#LOAD GAN DISCRIMINATOR\n",
    "model_dis = Discriminator()\n",
    "model_dis.load_state_dict(torch.load('gan_dis.torch'))\n",
    "model_dis.to(device)\n",
    "model_dis.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate VAE (1000 images)\n",
    "img_path=\"1000_img_vae/\"\n",
    "noise = torch.randn(1000, 100, device=device)\n",
    "fake = model_vae.decode(noise)\n",
    "fake = fake.detach().cpu()\n",
    "\n",
    "for i in range(1000):\n",
    "    figname = \"vae_{}.png\".format(i)\n",
    "    save_image(fake[i,:,:,:].unsqueeze(0),os.path.join(img_path, figname),normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate GAN(1000 images)\n",
    "img_path=\"1000_img_gan/\"\n",
    "noise = torch.randn(1000, 100, 1, 1, device=device)\n",
    "fake = model_gen(noise)\n",
    "fake = fake.detach().cpu()\n",
    "\n",
    "for i in range(1000):\n",
    "    figname = \"gan_{}.png\".format(i)\n",
    "    save_image(fake[i,:,:,:].unsqueeze(0),os.path.join(img_path, figname),normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
